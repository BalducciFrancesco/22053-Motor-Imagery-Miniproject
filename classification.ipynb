{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa96b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fbf0c",
   "metadata": {},
   "source": [
    "# _TODO_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f4501",
   "metadata": {},
   "source": [
    "# Import EEG data\n",
    "Imports the `pre-processed.p` file generated by the [pre-processing notebook](preprocessing.ipynb).\n",
    "\n",
    "Shapes:\n",
    "- X: `(subject, trials, components, bands)`\n",
    "- y: `(subject, trials)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b69c794f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1: 434 trials, 6 components, 2 bands average power\n",
      "Subject 2: 434 trials, 6 components, 2 bands average power\n",
      "Subject 3: 434 trials, 6 components, 2 bands average power\n",
      "Subject 4: 434 trials, 6 components, 2 bands average power\n",
      "Subject 5: 434 trials, 6 components, 2 bands average power\n",
      "Subject 6: 434 trials, 6 components, 2 bands average power\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('preprocessed.p', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "n_subjects = X.shape[0]\n",
    "for i, subj in enumerate(X):\n",
    "    n_trials, n_components, n_bands = subj.shape\n",
    "    print(f\"Subject {i+1}: {n_trials} trials, {n_components} components, {n_bands} bands average power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "495d7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dummy data (random matrix with same shape as EEG data)\n",
    "# rng = np.random.default_rng(42)\n",
    "# X = rng.standard_normal((6, 434, 6, 2)).astype(np.float32)\n",
    "# y = rng.integers(0, 2, size=(6, 434), dtype=np.int8)\n",
    "\n",
    "# n_subjects = X.shape[0]\n",
    "# for i, subj in enumerate(X):\n",
    "#     n_trials, n_components, n_bands = subj.shape\n",
    "#     print(f\"Subject {i+1}: {n_trials} trials, {n_components} components, {n_bands} bands' average power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6926278",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19dece3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = one per trial and subject, columns = features (average power of two bands for each component)\n",
    "X_svm = X.reshape(n_subjects * n_trials, n_components * n_bands)  \n",
    "y_svm = y.reshape(n_subjects * n_trials)\n",
    "# for each row, which subject it belongs to\n",
    "subject_ids = np.repeat(np.arange(n_subjects), n_trials)  # shape = (n_subjects * n_trials,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95143c",
   "metadata": {},
   "source": [
    "## Inter-subject (LeaveOneGroupOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d548089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject left out for testing: 0\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1127 1043]\n",
      "Testing set class distribution (0s and 1s): [217 217]\n",
      "Testing set predictions accuracy: 0.5\n",
      "\n",
      "Subject left out for testing: 1\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1106 1064]\n",
      "Testing set class distribution (0s and 1s): [238 196]\n",
      "Testing set predictions accuracy: 0.511520737327189\n",
      "\n",
      "Subject left out for testing: 2\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1122 1048]\n",
      "Testing set class distribution (0s and 1s): [222 212]\n",
      "Testing set predictions accuracy: 0.5069124423963134\n",
      "\n",
      "Subject left out for testing: 3\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1123 1047]\n",
      "Testing set class distribution (0s and 1s): [221 213]\n",
      "Testing set predictions accuracy: 0.511520737327189\n",
      "\n",
      "Subject left out for testing: 4\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1136 1034]\n",
      "Testing set class distribution (0s and 1s): [208 226]\n",
      "Testing set predictions accuracy: 0.4792626728110599\n",
      "\n",
      "Subject left out for testing: 5\n",
      "Training on 2170 samples, testing on 434 samples\n",
      "Training set class distribution (0s and 1s): [1106 1064]\n",
      "Testing set class distribution (0s and 1s): [238 196]\n",
      "Testing set predictions accuracy: 0.5483870967741935\n",
      "\n",
      "Average cross-subject accuracy: 0.5096006144393241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scores = [] # one accuracy score per subject left out\n",
    "for train_idx, test_idx in LeaveOneGroupOut().split(X_svm, y_svm, groups=subject_ids):  # number of iterations = n_subjects\n",
    "    X_train, X_test = X_svm[train_idx], X_svm[test_idx]\n",
    "    y_train, y_test = y_svm[train_idx], y_svm[test_idx]\n",
    "\n",
    "    print(\"\\nSubject left out for testing:\", subject_ids[test_idx[0]])\n",
    "    print(f\"Training on {X_train.shape[0]} samples, testing on {X_test.shape[0]} samples\")\n",
    "    print(\"Training set class distribution (0s and 1s):\", np.bincount(y_train))\n",
    "    print(\"Testing set class distribution (0s and 1s):\", np.bincount(y_test))\n",
    "\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Testing set predictions accuracy:\", score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"\\nAverage cross-subject accuracy:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11185e6",
   "metadata": {},
   "source": [
    "## Intra-subject (K-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a09ce6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer fold 1:\n",
      "Training on 2083 samples, testing on 521 samples\n",
      "Training set class distribution (0s and 1s): [1075 1008]\n",
      "Testing set class distribution (0s and 1s): [269 252]\n",
      "Mean accuracy on test set: 0.5489443378119002\n",
      "Best C found in inner CV: 0.1\n",
      "\n",
      "Outer fold 2:\n",
      "Training on 2083 samples, testing on 521 samples\n",
      "Training set class distribution (0s and 1s): [1075 1008]\n",
      "Testing set class distribution (0s and 1s): [269 252]\n",
      "Mean accuracy on test set: 0.5412667946257198\n",
      "Best C found in inner CV: 1\n",
      "\n",
      "Outer fold 3:\n",
      "Training on 2083 samples, testing on 521 samples\n",
      "Training set class distribution (0s and 1s): [1075 1008]\n",
      "Testing set class distribution (0s and 1s): [269 252]\n",
      "Mean accuracy on test set: 0.5758157389635317\n",
      "Best C found in inner CV: 0.1\n",
      "\n",
      "Outer fold 4:\n",
      "Training on 2083 samples, testing on 521 samples\n",
      "Training set class distribution (0s and 1s): [1075 1008]\n",
      "Testing set class distribution (0s and 1s): [269 252]\n",
      "Mean accuracy on test set: 0.5393474088291746\n",
      "Best C found in inner CV: 10\n",
      "\n",
      "Outer fold 5:\n",
      "Training on 2084 samples, testing on 520 samples\n",
      "Training set class distribution (0s and 1s): [1076 1008]\n",
      "Testing set class distribution (0s and 1s): [268 252]\n",
      "Mean accuracy on test set: 0.575\n",
      "Best C found in inner CV: 10\n",
      "\n",
      "Overall average accuracy across outer folds: 0.5560748560460652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"linear\"))\n",
    "])\n",
    "\n",
    "# Parameters that will be tested in the inner cross-validation:\n",
    "# for each outer fold, the inner CV will select the best C among these values\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.01, 0.1, 1, 10]    # Possible values for the SVM regularization parameter C\n",
    "}\n",
    "\n",
    "scores = []     # to store the accuracy scores from each outer fold\n",
    "best_Cs = []    # to store the best C found in each outer fold\n",
    "for train_idx, test_idx in outer_cv.split(X_svm, y_svm):\n",
    "    X_train, X_test = X_svm[train_idx], X_svm[test_idx]\n",
    "    y_train, y_test = y_svm[train_idx], y_svm[test_idx]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid,\n",
    "        cv=inner_cv,\n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    scores.append(grid.score(X_test, y_test))\n",
    "    best_Cs.append(grid.best_params_[\"svm__C\"])\n",
    "\n",
    "    print(f\"\\nOuter fold {len(scores)}:\")\n",
    "    print(f\"Training on {X_train.shape[0]} samples, testing on {X_test.shape[0]} samples\")\n",
    "    print(\"Training set class distribution (0s and 1s):\", np.bincount(y_train))\n",
    "    print(\"Testing set class distribution (0s and 1s):\", np.bincount(y_test))\n",
    "    print(\"Mean accuracy on test set:\", scores[-1])\n",
    "    print(\"Best C found in inner CV:\", best_Cs[-1])\n",
    "\n",
    "print(\"\\nOverall average accuracy across outer folds:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5de2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c49be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
